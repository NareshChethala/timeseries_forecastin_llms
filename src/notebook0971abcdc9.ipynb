{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13376070,"sourceType":"datasetVersion","datasetId":8486328}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:30:19.633958Z","iopub.execute_input":"2025-10-14T02:30:19.634640Z","iopub.status.idle":"2025-10-14T02:30:21.208971Z","shell.execute_reply.started":"2025-10-14T02:30:19.634613Z","shell.execute_reply":"2025-10-14T02:30:21.208301Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sp-nasdaq-07-23/during_pre_post.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# !pip install pandas matplotlib seaborn scikit-learn transformers datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:30:21.210015Z","iopub.execute_input":"2025-10-14T02:30:21.210391Z","iopub.status.idle":"2025-10-14T02:30:21.213918Z","shell.execute_reply.started":"2025-10-14T02:30:21.210372Z","shell.execute_reply":"2025-10-14T02:30:21.213097Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install plotnine","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:30:21.214767Z","iopub.execute_input":"2025-10-14T02:30:21.215052Z","iopub.status.idle":"2025-10-14T02:30:39.004610Z","shell.execute_reply.started":"2025-10-14T02:30:21.215025Z","shell.execute_reply":"2025-10-14T02:30:39.003747Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: plotnine in /usr/local/lib/python3.11/dist-packages (0.14.5)\nCollecting matplotlib>=3.8.0 (from plotnine)\n  Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from plotnine) (2.2.3)\nRequirement already satisfied: mizani~=0.13.0 in /usr/local/lib/python3.11/dist-packages (from plotnine) (0.13.5)\nRequirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from plotnine) (1.26.4)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from plotnine) (1.15.3)\nRequirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from plotnine) (0.14.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->plotnine) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->plotnine) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->plotnine) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->plotnine) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->plotnine) (25.0)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->plotnine) (11.3.0)\nRequirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->plotnine) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->plotnine) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->plotnine) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->plotnine) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->plotnine) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->plotnine) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->plotnine) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->plotnine) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->plotnine) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->plotnine) (2025.2)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->plotnine) (1.0.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->plotnine) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.5->plotnine) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.5->plotnine) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.5->plotnine) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.5->plotnine) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.5->plotnine) (2024.2.0)\nDownloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: matplotlib\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.2\n    Uninstalling matplotlib-3.7.2:\n      Successfully uninstalled matplotlib-3.7.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed matplotlib-3.10.7\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# !pip3 install torch torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:30:39.006820Z","iopub.execute_input":"2025-10-14T02:30:39.007133Z","iopub.status.idle":"2025-10-14T02:30:39.010713Z","shell.execute_reply.started":"2025-10-14T02:30:39.007107Z","shell.execute_reply":"2025-10-14T02:30:39.010174Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom transformers import BertTokenizer, BertModel\nfrom datasets import Dataset\nfrom plotnine import *\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:30:39.011401Z","iopub.execute_input":"2025-10-14T02:30:39.011615Z","iopub.status.idle":"2025-10-14T02:31:06.235696Z","shell.execute_reply.started":"2025-10-14T02:30:39.011593Z","shell.execute_reply":"2025-10-14T02:31:06.235120Z"}},"outputs":[{"name":"stderr","text":"2025-10-14 02:30:54.730530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760409054.908365      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760409054.958700      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sp-nasdaq-07-23/during_pre_post.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:06.236486Z","iopub.execute_input":"2025-10-14T02:31:06.236962Z","iopub.status.idle":"2025-10-14T02:31:10.622517Z","shell.execute_reply.started":"2025-10-14T02:31:06.236942Z","shell.execute_reply":"2025-10-14T02:31:10.621690Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:10.623380Z","iopub.execute_input":"2025-10-14T02:31:10.623609Z","iopub.status.idle":"2025-10-14T02:31:10.647190Z","shell.execute_reply.started":"2025-10-14T02:31:10.623592Z","shell.execute_reply":"2025-10-14T02:31:10.646440Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   tickerdate tickertime index_symbol market_phase     open     high      low  \\\n0  2007-10-26   11:59:00          SPX    GFC_Crash  1523.00  1523.00  1521.97   \n1  2007-11-02   12:47:00          SPX    GFC_Crash  1508.00  1508.50  1508.00   \n2  2007-11-21   15:37:00          SPX    GFC_Crash  1425.00  1425.00  1423.97   \n3  2007-12-11   10:37:00          SPX    GFC_Crash  1515.16  1515.16  1515.00   \n4  2008-02-20   15:49:00          SPX    GFC_Crash  1357.00  1357.00  1356.31   \n\n     close  \n0  1521.97  \n1  1508.46  \n2  1424.25  \n3  1515.00  \n4  1356.61  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tickerdate</th>\n      <th>tickertime</th>\n      <th>index_symbol</th>\n      <th>market_phase</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-10-26</td>\n      <td>11:59:00</td>\n      <td>SPX</td>\n      <td>GFC_Crash</td>\n      <td>1523.00</td>\n      <td>1523.00</td>\n      <td>1521.97</td>\n      <td>1521.97</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-11-02</td>\n      <td>12:47:00</td>\n      <td>SPX</td>\n      <td>GFC_Crash</td>\n      <td>1508.00</td>\n      <td>1508.50</td>\n      <td>1508.00</td>\n      <td>1508.46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-11-21</td>\n      <td>15:37:00</td>\n      <td>SPX</td>\n      <td>GFC_Crash</td>\n      <td>1425.00</td>\n      <td>1425.00</td>\n      <td>1423.97</td>\n      <td>1424.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-12-11</td>\n      <td>10:37:00</td>\n      <td>SPX</td>\n      <td>GFC_Crash</td>\n      <td>1515.16</td>\n      <td>1515.16</td>\n      <td>1515.00</td>\n      <td>1515.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-02-20</td>\n      <td>15:49:00</td>\n      <td>SPX</td>\n      <td>GFC_Crash</td>\n      <td>1357.00</td>\n      <td>1357.00</td>\n      <td>1356.31</td>\n      <td>1356.61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Drop column \"market_phase\"\ndf = df.drop(columns=[\"market_phase\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:10.647945Z","iopub.execute_input":"2025-10-14T02:31:10.648229Z","iopub.status.idle":"2025-10-14T02:31:10.782248Z","shell.execute_reply.started":"2025-10-14T02:31:10.648205Z","shell.execute_reply":"2025-10-14T02:31:10.781364Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# separate the dataframe based on \"index_symbol\"\ndf_list = [group for _, group in df.groupby(\"index_symbol\")]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:10.783084Z","iopub.execute_input":"2025-10-14T02:31:10.783289Z","iopub.status.idle":"2025-10-14T02:31:11.204537Z","shell.execute_reply.started":"2025-10-14T02:31:10.783272Z","shell.execute_reply":"2025-10-14T02:31:11.203929Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"spx_df = df[df['index_symbol'] == 'SPX']\nndx_df = df[df['index_symbol'] == 'NDX']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:11.206780Z","iopub.execute_input":"2025-10-14T02:31:11.206998Z","iopub.status.idle":"2025-10-14T02:31:11.724575Z","shell.execute_reply.started":"2025-10-14T02:31:11.206981Z","shell.execute_reply":"2025-10-14T02:31:11.723936Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"spx_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:11.725251Z","iopub.execute_input":"2025-10-14T02:31:11.725458Z","iopub.status.idle":"2025-10-14T02:31:11.734986Z","shell.execute_reply.started":"2025-10-14T02:31:11.725442Z","shell.execute_reply":"2025-10-14T02:31:11.734481Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   tickerdate tickertime index_symbol     open     high      low    close\n0  2007-10-26   11:59:00          SPX  1523.00  1523.00  1521.97  1521.97\n1  2007-11-02   12:47:00          SPX  1508.00  1508.50  1508.00  1508.46\n2  2007-11-21   15:37:00          SPX  1425.00  1425.00  1423.97  1424.25\n3  2007-12-11   10:37:00          SPX  1515.16  1515.16  1515.00  1515.00\n4  2008-02-20   15:49:00          SPX  1357.00  1357.00  1356.31  1356.61","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tickerdate</th>\n      <th>tickertime</th>\n      <th>index_symbol</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-10-26</td>\n      <td>11:59:00</td>\n      <td>SPX</td>\n      <td>1523.00</td>\n      <td>1523.00</td>\n      <td>1521.97</td>\n      <td>1521.97</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-11-02</td>\n      <td>12:47:00</td>\n      <td>SPX</td>\n      <td>1508.00</td>\n      <td>1508.50</td>\n      <td>1508.00</td>\n      <td>1508.46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-11-21</td>\n      <td>15:37:00</td>\n      <td>SPX</td>\n      <td>1425.00</td>\n      <td>1425.00</td>\n      <td>1423.97</td>\n      <td>1424.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-12-11</td>\n      <td>10:37:00</td>\n      <td>SPX</td>\n      <td>1515.16</td>\n      <td>1515.16</td>\n      <td>1515.00</td>\n      <td>1515.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-02-20</td>\n      <td>15:49:00</td>\n      <td>SPX</td>\n      <td>1357.00</td>\n      <td>1357.00</td>\n      <td>1356.31</td>\n      <td>1356.61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"spx_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:11.735653Z","iopub.execute_input":"2025-10-14T02:31:11.735907Z","iopub.status.idle":"2025-10-14T02:31:11.973430Z","shell.execute_reply.started":"2025-10-14T02:31:11.735882Z","shell.execute_reply":"2025-10-14T02:31:11.972818Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 1537664 entries, 0 to 1537663\nData columns (total 7 columns):\n #   Column        Non-Null Count    Dtype  \n---  ------        --------------    -----  \n 0   tickerdate    1537664 non-null  object \n 1   tickertime    1537664 non-null  object \n 2   index_symbol  1537664 non-null  object \n 3   open          1537664 non-null  float64\n 4   high          1537664 non-null  float64\n 5   low           1537664 non-null  float64\n 6   close         1537664 non-null  float64\ndtypes: float64(4), object(3)\nmemory usage: 93.9+ MB\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"spx = spx_df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:11.974161Z","iopub.execute_input":"2025-10-14T02:31:11.974365Z","iopub.status.idle":"2025-10-14T02:31:12.033076Z","shell.execute_reply.started":"2025-10-14T02:31:11.974350Z","shell.execute_reply":"2025-10-14T02:31:12.032282Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"spx[\"datetime\"] = pd.to_datetime(spx[\"tickerdate\"] + \" \" + spx[\"tickertime\"])\nspx = spx.sort_values(\"datetime\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:12.033907Z","iopub.execute_input":"2025-10-14T02:31:12.034282Z","iopub.status.idle":"2025-10-14T02:31:12.818166Z","shell.execute_reply.started":"2025-10-14T02:31:12.034257Z","shell.execute_reply":"2025-10-14T02:31:12.817344Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"spx = spx.set_index(\"datetime\")[[\"open\",\"high\",\"low\",\"close\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:12.819032Z","iopub.execute_input":"2025-10-14T02:31:12.819825Z","iopub.status.idle":"2025-10-14T02:31:12.895155Z","shell.execute_reply.started":"2025-10-14T02:31:12.819794Z","shell.execute_reply":"2025-10-14T02:31:12.894474Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"SESSION_START = \"09:30\"\nSESSION_END   = \"16:00\"\n\nis_weekday = spx.index.weekday < 5\nhhmm = spx.index.strftime(\"%H:%M\")\nin_session = (hhmm >= SESSION_START) & (hhmm <= SESSION_END)\n\nspx = spx.loc[is_weekday & in_session].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:12.895837Z","iopub.execute_input":"2025-10-14T02:31:12.896047Z","iopub.status.idle":"2025-10-14T02:31:18.330773Z","shell.execute_reply.started":"2025-10-14T02:31:12.896030Z","shell.execute_reply":"2025-10-14T02:31:18.329785Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# filter only the last 5 years\nend_dt = spx.index.max()\ncutoff = end_dt - pd.DateOffset(years=5)\nspx = spx.loc[spx.index >= cutoff].copy()\n\nprint(\"Date range:\", spx.index.min(), \"→\", spx.index.max())\nprint(\"Rows after 5y filter:\", len(spx))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.331707Z","iopub.execute_input":"2025-10-14T02:31:18.332037Z","iopub.status.idle":"2025-10-14T02:31:18.372875Z","shell.execute_reply.started":"2025-10-14T02:31:18.332015Z","shell.execute_reply":"2025-10-14T02:31:18.372150Z"}},"outputs":[{"name":"stdout","text":"Date range: 2018-03-26 09:30:00 → 2023-03-24 16:00:00\nRows after 5y filter: 490637\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"spx[\"log_return\"] = np.log(spx[\"close\"] / spx[\"close\"].shift(1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.373605Z","iopub.execute_input":"2025-10-14T02:31:18.373817Z","iopub.status.idle":"2025-10-14T02:31:18.439217Z","shell.execute_reply.started":"2025-10-14T02:31:18.373798Z","shell.execute_reply":"2025-10-14T02:31:18.438380Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# time features (cyclic encodings, as used in Informer/FEDformer-style setups)\nspx[\"month\"]   = spx.index.month\nspx[\"weekday\"] = spx.index.weekday\nspx[\"hour\"]    = spx.index.hour\nspx[\"minute\"]  = spx.index.minute","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.440038Z","iopub.execute_input":"2025-10-14T02:31:18.440693Z","iopub.status.idle":"2025-10-14T02:31:18.490896Z","shell.execute_reply.started":"2025-10-14T02:31:18.440671Z","shell.execute_reply":"2025-10-14T02:31:18.490348Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"spx[\"month_sin\"]   = np.sin(2*np.pi*spx[\"month\"]/12)\nspx[\"month_cos\"]   = np.cos(2*np.pi*spx[\"month\"]/12)\nspx[\"weekday_sin\"] = np.sin(2*np.pi*spx[\"weekday\"]/7)\nspx[\"weekday_cos\"] = np.cos(2*np.pi*spx[\"weekday\"]/7)\nspx[\"hour_sin\"]    = np.sin(2*np.pi*spx[\"hour\"]/24)\nspx[\"hour_cos\"]    = np.cos(2*np.pi*spx[\"hour\"]/24)\nspx[\"minute_sin\"]  = np.sin(2*np.pi*spx[\"minute\"]/60)\nspx[\"minute_cos\"]  = np.cos(2*np.pi*spx[\"minute\"]/60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.491633Z","iopub.execute_input":"2025-10-14T02:31:18.491836Z","iopub.status.idle":"2025-10-14T02:31:18.527409Z","shell.execute_reply.started":"2025-10-14T02:31:18.491820Z","shell.execute_reply":"2025-10-14T02:31:18.526641Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#drop the first NaN from log_return\nspx = spx.dropna(subset=[\"log_return\"]).copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.528178Z","iopub.execute_input":"2025-10-14T02:31:18.528378Z","iopub.status.idle":"2025-10-14T02:31:18.680099Z","shell.execute_reply.started":"2025-10-14T02:31:18.528362Z","shell.execute_reply":"2025-10-14T02:31:18.679229Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"TIME_FEATS = [\n    \"month_sin\",\"month_cos\",\n    \"weekday_sin\",\"weekday_cos\",\n    \"hour_sin\",\"hour_cos\",\n    \"minute_sin\",\"minute_cos\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.681081Z","iopub.execute_input":"2025-10-14T02:31:18.681337Z","iopub.status.idle":"2025-10-14T02:31:18.685215Z","shell.execute_reply.started":"2025-10-14T02:31:18.681320Z","shell.execute_reply":"2025-10-14T02:31:18.684343Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# model will see past log_return + these time features\nMODEL_FEATS = [\"log_return\"] + TIME_FEATS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.685901Z","iopub.execute_input":"2025-10-14T02:31:18.686132Z","iopub.status.idle":"2025-10-14T02:31:18.703908Z","shell.execute_reply.started":"2025-10-14T02:31:18.686113Z","shell.execute_reply":"2025-10-14T02:31:18.703166Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.704677Z","iopub.execute_input":"2025-10-14T02:31:18.705308Z","iopub.status.idle":"2025-10-14T02:31:18.719860Z","shell.execute_reply.started":"2025-10-14T02:31:18.705284Z","shell.execute_reply":"2025-10-14T02:31:18.719115Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# sort te dataframe\nspx = spx.sort_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.720571Z","iopub.execute_input":"2025-10-14T02:31:18.720760Z","iopub.status.idle":"2025-10-14T02:31:18.756107Z","shell.execute_reply.started":"2025-10-14T02:31:18.720746Z","shell.execute_reply":"2025-10-14T02:31:18.755500Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# list unique trading days \ntrading_days = np.array(sorted({ts.date() for ts in spx.index}))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:18.756736Z","iopub.execute_input":"2025-10-14T02:31:18.756913Z","iopub.status.idle":"2025-10-14T02:31:19.908810Z","shell.execute_reply.started":"2025-10-14T02:31:18.756899Z","shell.execute_reply":"2025-10-14T02:31:19.908024Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# compute day-based boundaries\nD = len(trading_days)\nd_train_end = int(D * 0.70)\nd_val_end   = int(D * 0.80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:19.909642Z","iopub.execute_input":"2025-10-14T02:31:19.909858Z","iopub.status.idle":"2025-10-14T02:31:19.913678Z","shell.execute_reply.started":"2025-10-14T02:31:19.909842Z","shell.execute_reply":"2025-10-14T02:31:19.912841Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# data split based on the day boundaries\ntrain_days = trading_days[:d_train_end]\nval_days   = trading_days[d_train_end:d_val_end]\ntest_days  = trading_days[d_val_end:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:19.916891Z","iopub.execute_input":"2025-10-14T02:31:19.917192Z","iopub.status.idle":"2025-10-14T02:31:19.929909Z","shell.execute_reply.started":"2025-10-14T02:31:19.917175Z","shell.execute_reply":"2025-10-14T02:31:19.929213Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# slice by full days (each split starts at that day’s first bar)\nspx_train = spx[np.isin(spx.index.date, train_days)].copy()\nspx_val   = spx[np.isin(spx.index.date, val_days)].copy()\nspx_test  = spx[np.isin(spx.index.date, test_days)].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:19.930609Z","iopub.execute_input":"2025-10-14T02:31:19.930838Z","iopub.status.idle":"2025-10-14T02:31:28.879448Z","shell.execute_reply.started":"2025-10-14T02:31:19.930816Z","shell.execute_reply":"2025-10-14T02:31:28.878823Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# scale ONLY log_return using TRAIN statistics\nscaler = StandardScaler().fit(spx_train[[\"log_return\"]])\nspx_train[\"log_return\"] = scaler.transform(spx_train[[\"log_return\"]])\nspx_val[\"log_return\"]   = scaler.transform(spx_val[[\"log_return\"]])\nspx_test[\"log_return\"]  = scaler.transform(spx_test[[\"log_return\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:28.880118Z","iopub.execute_input":"2025-10-14T02:31:28.880284Z","iopub.status.idle":"2025-10-14T02:31:28.899426Z","shell.execute_reply.started":"2025-10-14T02:31:28.880270Z","shell.execute_reply":"2025-10-14T02:31:28.898832Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"X_train = spx_train[MODEL_FEATS].to_numpy(dtype=\"float32\")\nX_val   = spx_val  [MODEL_FEATS].to_numpy(dtype=\"float32\")\nX_test  = spx_test [MODEL_FEATS].to_numpy(dtype=\"float32\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:28.900081Z","iopub.execute_input":"2025-10-14T02:31:28.900302Z","iopub.status.idle":"2025-10-14T02:31:28.957575Z","shell.execute_reply.started":"2025-10-14T02:31:28.900286Z","shell.execute_reply":"2025-10-14T02:31:28.956794Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# sanity check: first timestamps should be around 09:30 (or first available bar)\nprint(\"Train start:\", spx_train.index.min())\nprint(\"Val   start:\", spx_val.index.min())\nprint(\"Test  start:\", spx_test.index.min())\nprint(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:28.958450Z","iopub.execute_input":"2025-10-14T02:31:28.958674Z","iopub.status.idle":"2025-10-14T02:31:28.964657Z","shell.execute_reply.started":"2025-10-14T02:31:28.958658Z","shell.execute_reply":"2025-10-14T02:31:28.963982Z"}},"outputs":[{"name":"stdout","text":"Train start: 2018-03-26 09:31:00\nVal   start: 2021-09-23 09:30:00\nTest  start: 2022-03-24 09:30:00\nShapes: (343198, 9) (49107, 9) (98331, 9)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Choosing the context window\nTin  = 330\nTout = 27\n\ndef make_windows(arr: np.ndarray, Tin: int, Tout: int):\n    X_enc, X_dec, Y = [], [], []\n    T, D = arr.shape\n    last_start = T - (Tin + Tout)\n    if last_start <= 0:\n        raise ValueError(\"Not enough rows for the chosen Tin/Tout.\")\n\n    for i in range(last_start):\n        enc = arr[i:i+Tin]                 \n        tgt = arr[i+Tin:i+Tin+Tout]         \n        start = np.zeros((1, D), dtype=np.float32)\n        dec_in = np.vstack([start, tgt[:-1]])\n        X_enc.append(enc)\n        X_dec.append(dec_in)\n        Y.append(tgt)\n\n    return (np.array(X_enc, dtype=np.float32),\n            np.array(X_dec, dtype=np.float32),\n            np.array(Y,     dtype=np.float32))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:28.965362Z","iopub.execute_input":"2025-10-14T02:31:28.965554Z","iopub.status.idle":"2025-10-14T02:31:28.980017Z","shell.execute_reply.started":"2025-10-14T02:31:28.965540Z","shell.execute_reply":"2025-10-14T02:31:28.979332Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# build arrays from your 70:10:20 day-aligned splits\nX_train_np = spx_train[MODEL_FEATS].to_numpy(dtype=np.float32)\nX_val_np   = spx_val  [MODEL_FEATS].to_numpy(dtype=np.float32)\nX_test_np  = spx_test [MODEL_FEATS].to_numpy(dtype=np.float32)\n\ntr_enc, tr_dec, tr_tgt = make_windows(X_train_np, Tin, Tout)\nva_enc, va_dec, va_tgt = make_windows(X_val_np,   Tin, Tout)\nte_enc, te_dec, te_tgt = make_windows(X_test_np,  Tin, Tout)\n\nprint(\"Train windows:\", tr_enc.shape, tr_dec.shape, tr_tgt.shape)\nprint(\"Val   windows:\", va_enc.shape, va_dec.shape, va_tgt.shape)\nprint(\"Test  windows:\", te_enc.shape, te_dec.shape, te_tgt.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:28.980803Z","iopub.execute_input":"2025-10-14T02:31:28.981011Z","iopub.status.idle":"2025-10-14T02:31:35.132499Z","shell.execute_reply.started":"2025-10-14T02:31:28.980995Z","shell.execute_reply":"2025-10-14T02:31:35.131884Z"}},"outputs":[{"name":"stdout","text":"Train windows: (342841, 330, 9) (342841, 27, 9) (342841, 27, 9)\nVal   windows: (48750, 330, 9) (48750, 27, 9) (48750, 27, 9)\nTest  windows: (97974, 330, 9) (97974, 27, 9) (97974, 27, 9)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:35.133178Z","iopub.execute_input":"2025-10-14T02:31:35.133390Z","iopub.status.idle":"2025-10-14T02:31:35.136851Z","shell.execute_reply.started":"2025-10-14T02:31:35.133374Z","shell.execute_reply":"2025-10-14T02:31:35.136202Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# convert numpy windows to PyTorch tensors\ntr_enc_t  = torch.from_numpy(tr_enc)   \ntr_dec_t  = torch.from_numpy(tr_dec)   \ntr_tgt_t  = torch.from_numpy(tr_tgt)  \n\nva_enc_t  = torch.from_numpy(va_enc)\nva_dec_t  = torch.from_numpy(va_dec)\nva_tgt_t  = torch.from_numpy(va_tgt)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:35.137632Z","iopub.execute_input":"2025-10-14T02:31:35.137879Z","iopub.status.idle":"2025-10-14T02:31:35.152935Z","shell.execute_reply.started":"2025-10-14T02:31:35.137841Z","shell.execute_reply":"2025-10-14T02:31:35.152310Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# datasets\ntrain_ds = TensorDataset(tr_enc_t, tr_dec_t, tr_tgt_t)\nval_ds   = TensorDataset(va_enc_t, va_dec_t, va_tgt_t)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:35.153721Z","iopub.execute_input":"2025-10-14T02:31:35.153963Z","iopub.status.idle":"2025-10-14T02:31:35.170633Z","shell.execute_reply.started":"2025-10-14T02:31:35.153942Z","shell.execute_reply":"2025-10-14T02:31:35.169924Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# loaders\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=True)\nval_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, drop_last=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:35.171226Z","iopub.execute_input":"2025-10-14T02:31:35.171410Z","iopub.status.idle":"2025-10-14T02:31:35.186362Z","shell.execute_reply.started":"2025-10-14T02:31:35.171397Z","shell.execute_reply":"2025-10-14T02:31:35.185764Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import math\nimport torch.nn as nn\n\nD = tr_enc.shape[2]   \n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=4096, dropout=0.1):\n        super().__init__()\n        self.drop = nn.Dropout(dropout)\n        pe = torch.zeros(max_len, d_model)\n        pos = torch.arange(0, max_len).unsqueeze(1).float()\n        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n        pe[:, 0::2] = torch.sin(pos * div)\n        pe[:, 1::2] = torch.cos(pos * div)\n        self.register_buffer(\"pe\", pe)\n    def forward(self, x):  # x: [S, B, E]\n        return self.drop(x + self.pe[:x.size(0)].unsqueeze(1))\n\nclass TinyTransformer(nn.Module):\n    def __init__(self, d_in, d_model=64, nhead=4, enc_layers=2, dec_layers=2, ff=128, dropout=0.1):\n        super().__init__()\n        self.inp = nn.Linear(d_in, d_model)\n        self.pos = PositionalEncoding(d_model, dropout=dropout)\n        self.tf  = nn.Transformer(\n            d_model=d_model, nhead=nhead,\n            num_encoder_layers=enc_layers, num_decoder_layers=dec_layers,\n            dim_feedforward=ff, dropout=dropout, batch_first=False\n        )\n        self.out = nn.Linear(d_model, d_in)\n\n    @staticmethod\n    def tgt_mask(sz, device):\n        m = torch.triu(torch.ones(sz, sz, device=device), diagonal=1).bool()\n        return torch.zeros(sz, sz, device=device).masked_fill(m, float('-inf'))\n\n    def forward(self, src, tgt):  # src: [Tin,B,D], tgt: [Tout,B,D]\n        src = self.pos(self.inp(src))\n        tgt = self.pos(self.inp(tgt))\n        mask = self.tgt_mask(tgt.size(0), tgt.device)\n        mem  = self.tf.encoder(src)\n        dec  = self.tf.decoder(tgt, mem, tgt_mask=mask)\n        return self.out(dec)  # [Tout,B,D]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:35.186989Z","iopub.execute_input":"2025-10-14T02:31:35.187194Z","iopub.status.idle":"2025-10-14T02:31:35.205724Z","shell.execute_reply.started":"2025-10-14T02:31:35.187179Z","shell.execute_reply":"2025-10-14T02:31:35.205148Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = TinyTransformer(d_in=D).to(device)\nopt = torch.optim.AdamW(model.parameters(), lr=1e-3)\nloss_fn = nn.MSELoss()\n\nEPOCHS = 10  \n\nfor epoch in range(1, EPOCHS+1):\n    # train\n    model.train()\n    train_loss, n_train = 0.0, 0\n\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch:02d} [Train]\", leave=False)\n    for enc, dec_in, tgt in pbar:\n        enc = enc.transpose(0,1).to(device)\n        dec = dec_in.transpose(0,1).to(device)\n        tgt = tgt.transpose(0,1).to(device)\n\n        opt.zero_grad()\n        out = model(enc, dec)\n        loss = loss_fn(out, tgt)\n        loss.backward()\n        opt.step()\n\n        train_loss += loss.item() * enc.size(1)\n        n_train    += enc.size(1)\n        pbar.set_postfix({\"batch_loss\": f\"{loss.item():.6f}\"})\n\n    train_loss /= n_train\n\n    # validate\n    model.eval()\n    val_loss, n_val = 0.0, 0\n    pbar = tqdm(val_loader, desc=f\"Epoch {epoch:02d} [Val]\", leave=False)\n    with torch.no_grad():\n        for enc, dec_in, tgt in pbar:\n            enc = enc.transpose(0,1).to(device)\n            dec = dec_in.transpose(0,1).to(device)\n            tgt = tgt.transpose(0,1).to(device)\n\n            out = model(enc, dec)\n            vloss = loss_fn(out, tgt)\n\n            val_loss += vloss.item() * enc.size(1)\n            n_val    += enc.size(1)\n            pbar.set_postfix({\"batch_loss\": f\"{vloss.item():.6f}\"})\n\n    val_loss /= n_val\n    print(f\"Epoch {epoch:02d} | train MSE={train_loss:.6f} | val MSE={val_loss:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:33:03.405592Z","iopub.execute_input":"2025-10-14T02:33:03.406300Z","iopub.status.idle":"2025-10-14T03:07:20.850846Z","shell.execute_reply.started":"2025-10-14T02:33:03.406275Z","shell.execute_reply":"2025-10-14T03:07:20.850266Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | train MSE=0.117676 | val MSE=0.084829\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 02 | train MSE=0.112937 | val MSE=0.083993\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 03 | train MSE=0.112296 | val MSE=0.084664\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 04 | train MSE=0.112131 | val MSE=0.084686\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 05 | train MSE=0.112466 | val MSE=0.084265\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 06 | train MSE=0.112559 | val MSE=0.085247\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 07 | train MSE=0.112379 | val MSE=0.084928\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 08 | train MSE=0.113038 | val MSE=0.085084\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 09 | train MSE=0.112025 | val MSE=0.084019\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | train MSE=0.112864 | val MSE=0.085510\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"torch.save(model.state_dict(), \"vanilla_transformer_330_27.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T03:15:42.146567Z","iopub.execute_input":"2025-10-14T03:15:42.147265Z","iopub.status.idle":"2025-10-14T03:15:42.160020Z","shell.execute_reply.started":"2025-10-14T03:15:42.147241Z","shell.execute_reply":"2025-10-14T03:15:42.159447Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"import joblib\njoblib.dump(scaler, \"scaler_log_return.joblib\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T03:16:04.676399Z","iopub.execute_input":"2025-10-14T03:16:04.676863Z","iopub.status.idle":"2025-10-14T03:16:04.683830Z","shell.execute_reply.started":"2025-10-14T03:16:04.676840Z","shell.execute_reply":"2025-10-14T03:16:04.683077Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"['scaler_log_return.joblib']"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"scaler = joblib.load(\"scaler_log_return.joblib\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T03:16:19.477165Z","iopub.execute_input":"2025-10-14T03:16:19.477425Z","iopub.status.idle":"2025-10-14T03:16:19.481667Z","shell.execute_reply.started":"2025-10-14T03:16:19.477407Z","shell.execute_reply":"2025-10-14T03:16:19.481028Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"@torch.no_grad()\ndef forecast_next(model, arr_tail, steps, device):\n    \"\"\"\n    arr_tail: np.array of shape [Tin, D] (normalized features)\n    steps:    Tout\n    returns:  np.array of shape [Tout, D] (normalized predictions)\n    \"\"\"\n    model.eval()\n    x = torch.from_numpy(arr_tail.astype(np.float32)).unsqueeze(1).to(device)  \n    start = torch.zeros(1, 1, arr_tail.shape[1], device=device)                \n    # encode once\n    mem = model.tf.encoder(model.pos(model.inp(x)))\n    dec_in = start\n    preds = []\n    for _ in range(steps):\n        de  = model.pos(model.inp(dec_in))\n        m   = model.tgt_mask(de.size(0), de.device)\n        out = model.tf.decoder(de, mem, tgt_mask=m)\n        y   = model.out(out[-1:])  # [1,1,D]\n        preds.append(y)\n        dec_in = torch.cat([dec_in, y], dim=0)\n    return torch.cat(preds, dim=0).squeeze(1).cpu().numpy() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T03:18:01.065450Z","iopub.execute_input":"2025-10-14T03:18:01.066166Z","iopub.status.idle":"2025-10-14T03:18:01.071790Z","shell.execute_reply.started":"2025-10-14T03:18:01.066142Z","shell.execute_reply":"2025-10-14T03:18:01.071057Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def directional_accuracy(y_true, y_pred, col=0):\n    return float((np.sign(y_true[:, col]) == np.sign(y_pred[:, col])).mean())\n\nmse_list, mae_list, da_list = [], [], []\n\nfor i in range(len(te_enc)):\n    yhat = forecast_next(model, te_enc[i], steps=Tout, device=device) \n    ytrue = te_tgt[i]                                                 \n    mse = np.mean((ytrue - yhat)**2)\n    mae = np.mean(np.abs(ytrue - yhat))\n    da  = directional_accuracy(ytrue, yhat, col=0) \n    mse_list.append(mse); mae_list.append(mae); da_list.append(da)\n\nprint(f\"Test MSE (avg): {np.mean(mse_list):.6f}\")\nprint(f\"Test MAE (avg): {np.mean(mae_list):.6f}\")\nprint(f\"Directional Accuracy on log_return (avg): {np.mean(da_list):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T03:18:30.414455Z","iopub.execute_input":"2025-10-14T03:18:30.414943Z","iopub.status.idle":"2025-10-14T03:19:44.924100Z","shell.execute_reply.started":"2025-10-14T03:18:30.414922Z","shell.execute_reply":"2025-10-14T03:19:44.922896Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/2919161579.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecast_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_enc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mytrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mte_tgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrue\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/2998590178.py\u001b[0m in \u001b[0;36mforecast_next\u001b[0;34m(model, arr_tail, steps, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mde\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mm\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0my\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [1,1,D]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    614\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m   1110\u001b[0m             x = self.norm2(\n\u001b[1;32m   1111\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m                 + self._mha_block(\n\u001b[0m\u001b[1;32m   1113\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_is_causal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_mha_block\u001b[0;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0mis_causal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     ) -> Tensor:\n\u001b[0;32m-> 1148\u001b[0;31m         x = self.multihead_attn(\n\u001b[0m\u001b[1;32m   1149\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0mmem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6415\u001b[0m         )\n\u001b[1;32m   6416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6417\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6418\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":54},{"cell_type":"code","source":"# import torch\n# import numpy as np\n\n# @torch.no_grad()\n# def evaluate_model(model, te_enc, te_tgt, Tout, device):\n#     model.eval()\n#     mse_list, mae_list, da_list = [], [], []\n\n#     for i in range(len(te_enc)):\n#         # Convert input to GPU tensor\n#         enc_tail = torch.from_numpy(te_enc[i].astype(np.float32)).to(device)\n\n#         # Get forecast directly in torch (keep GPU)\n#         yhat_torch = forecast_next(model, te_enc[i], steps=Tout, device=device)\n#         yhat = torch.from_numpy(yhat_torch).to(device)\n#         ytrue = torch.from_numpy(te_tgt[i].astype(np.float32)).to(device)\n\n#         # Compute metrics (all on GPU)\n#         mse = torch.mean((ytrue - yhat) ** 2).item()\n#         mae = torch.mean(torch.abs(ytrue - yhat)).item()\n#         da  = torch.mean((torch.sign(ytrue[:, 0]) == torch.sign(yhat[:, 0])).float()).item()\n\n#         mse_list.append(mse)\n#         mae_list.append(mae)\n#         da_list.append(da)\n\n#         del yhat, ytrue, enc_tail\n#         torch.cuda.empty_cache()  # optional cleanup for memory safety\n\n#     print(f\"Test MSE (avg): {np.mean(mse_list):.6f}\")\n#     print(f\"Test MAE (avg): {np.mean(mae_list):.6f}\")\n#     print(f\"Directional Accuracy (avg): {np.mean(da_list):.3f}\")\nimport torch\nimport numpy as np\nfrom tqdm.notebook import tqdm   # notebook-friendly progress bar\n\n@torch.no_grad()\ndef evaluate_model(model, te_enc, te_tgt, Tout, device):\n    model.eval()\n    mse_list, mae_list, da_list = [], [], []\n\n    # tqdm shows progress + estimated time\n    for i in tqdm(range(len(te_enc)), desc=\"Evaluating test samples\"):\n        # Convert input to GPU tensor\n        enc_tail = torch.from_numpy(te_enc[i].astype(np.float32)).to(device)\n\n        # Get forecast directly in torch (keep GPU)\n        yhat_torch = forecast_next(model, te_enc[i], steps=Tout, device=device)\n        yhat = torch.from_numpy(yhat_torch).to(device)\n        ytrue = torch.from_numpy(te_tgt[i].astype(np.float32)).to(device)\n\n        # Compute metrics (all on GPU)\n        mse = torch.mean((ytrue - yhat) ** 2).item()\n        mae = torch.mean(torch.abs(ytrue - yhat)).item()\n        da  = torch.mean((torch.sign(ytrue[:, 0]) == torch.sign(yhat[:, 0])).float()).item()\n\n        mse_list.append(mse)\n        mae_list.append(mae)\n        da_list.append(da)\n\n        # free memory\n        del yhat, ytrue, enc_tail\n        torch.cuda.empty_cache()\n\n    # after loop finishes\n    print(\"\\n✅ Evaluation completed:\")\n    print(f\"Test MSE (avg): {np.mean(mse_list):.6f}\")\n    print(f\"Test MAE (avg): {np.mean(mae_list):.6f}\")\n    print(f\"Directional Accuracy (avg): {np.mean(da_list):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T03:39:19.566618Z","iopub.execute_input":"2025-10-14T03:39:19.567322Z","iopub.status.idle":"2025-10-14T03:39:19.574607Z","shell.execute_reply.started":"2025-10-14T03:39:19.567298Z","shell.execute_reply":"2025-10-14T03:39:19.573776Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"evaluate_model(model, te_enc, te_tgt, Tout, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T03:39:26.675723Z","iopub.execute_input":"2025-10-14T03:39:26.675991Z","iopub.status.idle":"2025-10-14T05:10:35.784366Z","shell.execute_reply.started":"2025-10-14T03:39:26.675971Z","shell.execute_reply":"2025-10-14T05:10:35.783583Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Evaluating test samples:   0%|          | 0/97974 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"470e34cc713b42c79a3d4368cc1c58d8"}},"metadata":{}},{"name":"stdout","text":"\n✅ Evaluation completed:\nTest MSE (avg): 0.139838\nTest MAE (avg): 0.108471\nDirectional Accuracy (avg): 0.499\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"# !nvidia-smi -L","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:35.224746Z","iopub.execute_input":"2025-10-14T02:31:35.225328Z","iopub.status.idle":"2025-10-14T02:31:35.426667Z","shell.execute_reply.started":"2025-10-14T02:31:35.225306Z","shell.execute_reply":"2025-10-14T02:31:35.425746Z"}},"outputs":[{"name":"stdout","text":"GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-78c96ead-07f6-79f6-2336-40485d2b2e96)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# import torch\n# print(\"GPUs available:\", torch.cuda.device_count())\n# print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU available\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:35.427860Z","iopub.execute_input":"2025-10-14T02:31:35.428283Z","iopub.status.idle":"2025-10-14T02:31:35.433246Z","shell.execute_reply.started":"2025-10-14T02:31:35.428249Z","shell.execute_reply":"2025-10-14T02:31:35.432491Z"}},"outputs":[{"name":"stdout","text":"GPUs available: 1\nGPU name: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# import torch\n# from torch import nn\n# from torch.cuda.amp import autocast, GradScaler\n# from tqdm import tqdm\n\n# # ---------------------------\n# # 1. GPU setup\n# # ---------------------------\n# if torch.cuda.is_available():\n#     print(f\"GPUs available: {torch.cuda.device_count()}\")\n#     for i in range(torch.cuda.device_count()):\n#         print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n# else:\n#     raise SystemError(\"No CUDA devices found.\")\n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # ---------------------------\n# # 2. Model setup\n# # ---------------------------\n# model = TinyTransformer(d_in=D)\n# if torch.cuda.device_count() > 1:\n#     # Parallelize across all GPUs\n#     model = nn.DataParallel(model)\n# model = model.to(device)\n\n# opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n# loss_fn = nn.MSELoss()\n# scaler = GradScaler()\n\n# torch.backends.cudnn.benchmark = True\n# torch.set_float32_matmul_precision(\"high\")\n\n# # ---------------------------\n# # 3. Training loop\n# # ---------------------------\n# EPOCHS = 10\n\n# for epoch in range(1, EPOCHS + 1):\n#     model.train()\n#     train_loss, n_train = 0.0, 0\n\n#     pbar = tqdm(train_loader, desc=f\"Epoch {epoch:02d} [Train]\")\n#     for enc, dec_in, tgt in pbar:\n#         enc = enc.transpose(0, 1).to(device, non_blocking=True)\n#         dec = dec_in.transpose(0, 1).to(device, non_blocking=True)\n#         tgt = tgt.transpose(0, 1).to(device, non_blocking=True)\n\n#         opt.zero_grad(set_to_none=True)\n\n#         with autocast():  # mixed precision\n#             out = model(enc, dec)\n#             loss = loss_fn(out, tgt)\n\n#         scaler.scale(loss).backward()\n#         scaler.step(opt)\n#         scaler.update()\n\n#         train_loss += loss.item() * enc.size(1)\n#         n_train += enc.size(1)\n#         pbar.set_postfix({\"batch_loss\": f\"{loss.item():.6f}\"})\n\n#         del loss, out  # release GPU memory\n\n#     train_loss /= n_train\n\n#     # ------------------ Validation ------------------\n#     model.eval()\n#     val_loss, n_val = 0.0, 0\n#     pbar = tqdm(val_loader, desc=f\"Epoch {epoch:02d} [Val]\")\n#     with torch.inference_mode(), autocast():\n#         for enc, dec_in, tgt in pbar:\n#             enc = enc.transpose(0, 1).to(device, non_blocking=True)\n#             dec = dec_in.transpose(0, 1).to(device, non_blocking=True)\n#             tgt = tgt.transpose(0, 1).to(device, non_blocking=True)\n\n#             out = model(enc, dec)\n#             vloss = loss_fn(out, tgt)\n\n#             val_loss += vloss.item() * enc.size(1)\n#             n_val += enc.size(1)\n#             pbar.set_postfix({\"batch_loss\": f\"{vloss.item():.6f}\"})\n\n#             del vloss, out\n\n#     val_loss /= n_val\n#     print(f\"Epoch {epoch:02d} | train MSE={train_loss:.6f} | val MSE={val_loss:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:35.434027Z","iopub.execute_input":"2025-10-14T02:31:35.434242Z","iopub.status.idle":"2025-10-14T02:31:35.448573Z","shell.execute_reply.started":"2025-10-14T02:31:35.434225Z","shell.execute_reply":"2025-10-14T02:31:35.447932Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# # If you're on GCP VM/Vertex/Colab TPU runtime these may already be present.\n# !pip -q install torch torch_xla==2.3 -f https://storage.googleapis.com/libtpu-releases/index.html\n\n# import os\n# os.environ[\"PJRT_DEVICE\"] = \"TPU\"     # use PJRT runtime on TPU v5e\n# os.environ[\"XLA_USE_BF16\"] = \"1\"      # bfloat16 for speed + memory\n# os.environ[\"XLA_IR_DEBUG\"] = \"0\"\n# os.environ[\"XLA_EXPERIMENTAL\"] = \"nonzero:masked_select_lowering\"  # minor perf tweak","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:31:35.449267Z","iopub.execute_input":"2025-10-14T02:31:35.449494Z","iopub.status.idle":"2025-10-14T02:32:55.864794Z","shell.execute_reply.started":"2025-10-14T02:31:35.449473Z","shell.execute_reply":"2025-10-14T02:32:55.864035Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h^C\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# import os\n# import math\n# import torch\n# from torch import nn\n# from torch.utils.data import DataLoader, DistributedSampler\n\n# # XLA imports\n# import torch_xla.core.xla_model as xm\n# import torch_xla.distributed.parallel_loader as pl\n# import torch_xla.distributed.xla_multiprocessing as xmp\n\n# # --------------------------\n# # Configs (tweak as needed)\n# # --------------------------\n# EPOCHS = 10\n# PER_CORE_BATCH = 64    # try 64–256; increase until ~80–90% HBM used\n# NUM_WORKERS = 4        # tune (2–8) based on your VM CPU\n# PRINT_EVERY = 1        # epochs\n\n# # --------------------------\n# # Your model / loss / opt\n# # --------------------------\n# def build_model_and_optim():\n#     model = TinyTransformer(d_in=D)\n#     loss_fn = nn.MSELoss()\n#     opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n#     return model, loss_fn, opt\n\n# # --------------------------\n# # Dataloaders per core\n# # --------------------------\n# def build_loaders():\n#     # IMPORTANT: per-core sampler so each TPU core sees unique data\n#     train_sampler = DistributedSampler(\n#         train_dataset,\n#         num_replicas=xm.xrt_world_size(),\n#         rank=xm.get_ordinal(),\n#         shuffle=True,\n#         drop_last=False,\n#     )\n#     val_sampler = DistributedSampler(\n#         val_dataset,\n#         num_replicas=xm.xrt_world_size(),\n#         rank=xm.get_ordinal(),\n#         shuffle=False,\n#         drop_last=False,\n#     )\n\n#     train_loader = DataLoader(\n#         train_dataset,\n#         batch_size=PER_CORE_BATCH,\n#         sampler=train_sampler,\n#         num_workers=NUM_WORKERS,\n#         pin_memory=False,     # pin_memory is a CUDA thing; off for TPU\n#         persistent_workers=True,\n#         drop_last=False,\n#     )\n#     val_loader = DataLoader(\n#         val_dataset,\n#         batch_size=PER_CORE_BATCH,\n#         sampler=val_sampler,\n#         num_workers=NUM_WORKERS,\n#         pin_memory=False,\n#         persistent_workers=True,\n#         drop_last=False,\n#     )\n#     return train_loader, val_loader, train_sampler, val_sampler\n\n# # --------------------------\n# # Train / Val loops on TPU\n# # --------------------------\n# def train_loop(rank):\n#     # Each process is bound to one TPU core\n#     device = xm.xla_device()\n\n#     model, loss_fn, opt = build_model_and_optim()\n#     model = model.to(device)\n\n#     train_loader, val_loader, train_sampler, val_sampler = build_loaders()\n\n#     # XLA wraps DataLoader so each core gets a device-bound iterator\n#     train_xla = pl.MpDeviceLoader(train_loader, device)\n#     val_xla   = pl.MpDeviceLoader(val_loader,   device)\n\n#     for epoch in range(1, EPOCHS + 1):\n#         # Ensure different shuffles per epoch across cores\n#         train_sampler.set_epoch(epoch)\n#         val_sampler.set_epoch(epoch)\n\n#         # ---------------- Train ----------------\n#         model.train()\n#         train_loss_sum = 0.0\n#         train_count    = 0\n\n#         for enc, dec_in, tgt in train_xla:\n#             # Keep logic identical, just on TPU device\n#             enc = enc.transpose(0, 1)  # [T,B,...]\n#             dec = dec_in.transpose(0, 1)\n#             tgt = tgt.transpose(0, 1)\n\n#             opt.zero_grad(set_to_none=True)\n\n#             # BF16 is enabled globally via XLA_USE_BF16, so no autocast needed\n#             out  = model(enc, dec)\n#             loss = loss_fn(out, tgt)\n\n#             loss.backward()\n#             # Use XLA optimizer step (executes graph & syncs grads)\n#             xm.optimizer_step(opt, barrier=True)\n\n#             # Local sums (avoid .item() in loop to reduce host syncs)\n#             bsz = enc.size(1)\n#             train_loss_sum += float(loss.detach()) * bsz\n#             train_count    += int(bsz)\n\n#             # Early delete to keep memory tidy\n#             del loss, out, enc, dec, tgt\n\n#         # Cross-core reduction to get global mean\n#         train_loss_sum = xm.mesh_reduce('train_loss_sum', train_loss_sum, sum)\n#         train_count    = xm.mesh_reduce('train_count',    train_count,    sum)\n#         train_mse = train_loss_sum / max(train_count, 1)\n\n#         # ---------------- Validate ----------------\n#         model.eval()\n#         val_loss_sum = 0.0\n#         val_count    = 0\n#         with torch.no_grad():\n#             for enc, dec_in, tgt in val_xla:\n#                 enc = enc.transpose(0, 1)\n#                 dec = dec_in.transpose(0, 1)\n#                 tgt = tgt.transpose(0, 1)\n\n#                 out   = model(enc, dec)\n#                 vloss = loss_fn(out, tgt)\n\n#                 bsz = enc.size(1)\n#                 val_loss_sum += float(vloss.detach()) * bsz\n#                 val_count    += int(bsz)\n\n#                 del vloss, out, enc, dec, tgt\n\n#         val_loss_sum = xm.mesh_reduce('val_loss_sum', val_loss_sum, sum)\n#         val_count    = xm.mesh_reduce('val_count',    val_count,    sum)\n#         val_mse = val_loss_sum / max(val_count, 1)\n\n#         # Print only once (core 0)\n#         if xm.is_master_ordinal() and (epoch % PRINT_EVERY == 1 or epoch == EPOCHS):\n#             print(f\"Epoch {epoch:02d} | train MSE={train_mse:.6f} | val MSE={val_mse:.6f}\")\n\n#     # Optional barrier to ensure all cores finish before exiting\n#     xm.rendezvous('training_done')\n\n# # ------------- Launch 8 TPU processes -------------\n# # v5e-8 has 8 chips/cores → spawn 8 workers\n# xmp.spawn(train_loop, args=(), nprocs=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T02:32:55.865800Z","iopub.execute_input":"2025-10-14T02:32:55.866027Z","iopub.status.idle":"2025-10-14T02:32:56.113334Z","shell.execute_reply.started":"2025-10-14T02:32:55.866008Z","shell.execute_reply":"2025-10-14T02:32:56.112306Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1302682579.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# XLA imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_loader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_multiprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_xla'"],"ename":"ModuleNotFoundError","evalue":"No module named 'torch_xla'","output_type":"error"}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}